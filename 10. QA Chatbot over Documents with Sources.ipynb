{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# QA Chatbot over Documents with Sources\n",
    "\n",
    "* [1. Setup](#setup)\n",
    "* [2. Scrapping for the News](#scrapping)\n",
    "* [3. Saving Embeddings](#saving)\n",
    "* [4. Setting up the Chain (RetrievalQAWithSourcesChain)](#chain)\n",
    "* [5. Run QA](#run)\n",
    "* [6. Additional Resources](#resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4f78c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"setup\">\n",
    "    \n",
    "## 1. Setup\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b34917",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q newspaper3k==0.2.8 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY, ACTIVELOOP_TOKEN\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d6c3b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"scrapping\">\n",
    "    \n",
    "## 2. Scrapping for the News\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51b8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests # to send HTTP requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time # to introduce pauses during the web scraping \n",
    "\n",
    "\n",
    "# To avoid blocking (if any) of requests without a proper User-Agent header \n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session() # to make multiple requests within the same session\n",
    "pages_content = [] # to store the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "        \n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6104e39",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"saving\">\n",
    "    \n",
    "## 3. Saving Embeddings\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ae04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "my_activeloop_org_id = \"iryna\"\n",
    "my_activeloop_dataset_name = \"qa_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16c27926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the article texts into small chunks. While doing so, we keep track of each\n",
    "# chunk metadata (i.e. the URL where it comes from). \n",
    "\n",
    "# Each metadata is a dictionary and we need to use the \"source\" key \n",
    "# for the document source so that we can then use the RetrievalQAWithSourcesChain \n",
    "# class which will automatically retrieve the \"source\" item from the metadata dictionary.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bf03c",
   "metadata": {},
   "source": [
    "**Note:** The `source` key is used in the metadata dictionary to align with the `RetrievalQAWithSourcesChain` class's expectations, which will automatically retrieve this \"source\" item from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1513de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://iryna/qa_with_source', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (49, 1536)  float32   None   \n",
      "    id        text      (49, 1)      str     None   \n",
      " metadata     json      (49, 1)      str     None   \n",
      "   text       text      (49, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fb7645a4-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7646c6-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76472a-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764784-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7647ca-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764810-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764860-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7648a6-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7648ec-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76493c-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764982-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7649c8-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764a0e-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764a5e-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764aa4-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764aea-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764b30-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764b76-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764bc6-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764c0c-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764c52-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764c98-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764cde-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764d2e-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764d74-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764dba-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764e0a-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764e50-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764e96-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764edc-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764f22-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764f72-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764fb8-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb764ffe-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765058-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76509e-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7650ee-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765134-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76517a-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7651c0-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765206-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765256-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76529c-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7652e2-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765328-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76536e-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb7653b4-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb765404-3fc9-11ee-aa24-12ee7aa5dbdc',\n",
       " 'fb76544a-3fc9-11ee-aa24-12ee7aa5dbdc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the chunks to the DeepLake, along with their metadata\n",
    "db.add_texts(all_texts, all_metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb9c99",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"chain\">\n",
    "    \n",
    "## 4. Setting up the Chain (RetrievalQAWithSourcesChain)\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648dd29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"RetrievalQAWithSourcesChain\" chain, which is very similar to a\n",
    "# standard retrieval QA chain but it also keeps track of the sources of the retrieved documents\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb07cb5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"run\">\n",
    "    \n",
    "## 5. Run QA\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13db0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a response to a query using the chain. \n",
    "response_dict = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b39ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Geoffrey Hinton believes that the rapid development of generative AI products is \"racing towards danger\" and that false text, images, and videos created by AI could lead to a situation where average people \"would not be able to know what is true anymore.\" He also expressed concerns about the impact of AI on the job market, as machines could eventually replace roles such as paralegals, personal assistants, and translators.\n",
      "\n",
      "Sources:\n",
      "- https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n"
     ]
    }
   ],
   "source": [
    "# The response object is a dictionary containing:\n",
    "# an \"answer\" field with the textual answer to the query, \n",
    "# a \"sources\" field containing a string made of the concatenation of the metadata[\"source\"] strings\n",
    "print(\"Response:\")\n",
    "print(response_dict[\"answer\"])\n",
    "\n",
    "print(\"Sources:\")\n",
    "for source in response_dict[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985c3c9",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"resources\">\n",
    "    \n",
    "## 6. Additional Resources\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df446b9",
   "metadata": {},
   "source": [
    "- [QA using a Langchain Retriever](https://python.langchain.com/docs/use_cases/question_answering/how_to/vector_db_qa)\n",
    "- [Activeloop's Deep Lake](https://python.langchain.com/docs/integrations/vectorstores/activeloop_deeplake)\n",
    "- [Vector Store Quickstart](https://docs.activeloop.ai/quickstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9234b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
