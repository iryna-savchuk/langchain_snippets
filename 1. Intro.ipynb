{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac34004",
   "metadata": {},
   "source": [
    "### The Power and Limitations of Large Language Models\n",
    "\n",
    "Large Language Models (LLMs) are trained to understand the distribution of words in a language, enabling them to **generate meaningful text** without memorizing specific data. However, their knowledge is limited to the training data, leading to potential fabrications when asked about information beyond their training period, known as **\"hallucination.\"**\n",
    "\n",
    "To address this issue, **retrievers** can be used alongside LLMs. Retrievers fetch information from trusted sources, and LLMs are prompted to rearrange the retrieved information without adding new details. LLMs like GPT-4 and Claude can handle large context window sizes, but an efficient retriever is needed to find the most relevant documents due to the cost of execution.\n",
    "\n",
    "Efficient retrievers are built using embedding models that map texts to vectors. These vectors are then stored in specialized databases called vector stores. This is where **Deep Lake** comes in: it provides a seamless way to store embeddings and their corresponding metadata. Deep Lake also enables hybrid searches on these embeddings and their attributes for efficient data retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253aa370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import ACTIVELOOP_TOKEN, OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3fb6a",
   "metadata": {},
   "source": [
    "### The LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3e8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LLM wrapper\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae214086",
   "metadata": {},
   "source": [
    "The temperature parameter in OpenAI models manages the randomness of the output.\n",
    "- 0: output is mostly predetermined and result is stable;\n",
    "- 1: output can be inconsistent and interesting, but isn't generally advised for most tasks;\n",
    "- between 0.70 and 0.90: offers a balance of reliability and creativity for creative tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5520ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GPT-3 model’s Davinci variant\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73ebf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "Day 1: \n",
      "• Begin with 10 minutes of light stretching \n",
      "• 3 sets of walking lunges with 20 reps per set \n",
      "• 2 sets of alternating leg lunges with 15 reps per set \n",
      "• 2 sets of high-knees with 30 reps per set \n",
      "• 30-minute jog at a moderate pace \n",
      "• 2 sets of burpees with 10 reps per set \n",
      "\n",
      "Day 2: \n",
      "• Begin with 10 minutes of light stretching \n",
      "• 3 sets of stair sprints with 10 reps per set \n",
      "• 2 sets of jump squats with 15 reps per set \n",
      "• 3 sets of mountain climbers with 20 reps per set\n",
      "• 30-minute jog at a moderate pace \n",
      "• 2 sets of hill sprints with 5 reps per set \n",
      "\n",
      "Day 3: \n",
      "• Begin with 10 minutes of light stretching \n",
      "• 3 sets of joggers with 20 reps per set \n",
      "• 2 sets of side skaters with 15 reps per set \n",
      "• 2 sets of butt kicks with 30 reps per set \n",
      "• 30-minute jog at a moderate pace \n",
      "• 2 sets of sprints with 10 reps per set\n"
     ]
    }
   ],
   "source": [
    "# Example of calling the initialized LLM\n",
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad2048",
   "metadata": {},
   "source": [
    "### The Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bbce7",
   "metadata": {},
   "source": [
    "A chain is a combination of multiple individual components in a specific sequence. The most commonly used type of chain is the **LLMChain**, which consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n",
    "\n",
    "The LLMChain works as follows:\n",
    "\n",
    "1. Takes input variable(s);\n",
    "2. Format the input variables into a prompt by using the PromptTemplate;\n",
    "3. Passes the formatted prompt to the model (LLM or ChatModel);\n",
    "4. Parses the output of the LLM into a final format, if an OutputParser is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8856daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a chain that generates a possible name for a company that produces a given product\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9, openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aaa7d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GreenDrop Water Bottles.\n"
     ]
    }
   ],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"eco-friendly water bottles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb1734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Steeped with Love Tea Co.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"personalized tea cups\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562fc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
