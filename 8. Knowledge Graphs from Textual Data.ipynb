{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# Creating Knowledge Graphs from Textual Data\n",
    "\n",
    "Knowledge graphs have emerged as a powerful way to visualize and explore connections between different pieces of information. They intend to transform unstructured text into a structured network of entities and their relationships.\n",
    "\n",
    "A knowledge graph is a knowledge base structured as a graph, where nodes represent entities and edges represent relations between those entities.\n",
    "\n",
    "The process of building a knowledge graph usually consists of **three sequential steps**:\n",
    "1. Named Entity Recognition (NER): extracting entities from the text that will become the nodes of the graph. It involves normalizing entities to the same entity, such as “Napoleon” and “Napoleon Bonapart” (which is usually done by linking them to a canonical source, like a Wikipedia page).\n",
    "2. Relation Classification (RC): extracting relations between entities that will form the edges of the graph. It can involve keeping track of the origin of each relation (such as the article URL and text span), which gives insights into the reliability of the extracted information (a relation is accurate if it can be extracted from several sources considered accurate).\n",
    "3. Knowledge graph visualization using libraries such as `pyvis`.\n",
    "\n",
    "**Named Entity Recognition + Relation Classification = Relation Extraction (RE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef350693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain==0.0.208 deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5953cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ce3971",
   "metadata": {},
   "source": [
    "### 1. Relation Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d680bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (Paris, is the capital of, France)<|>(Paris, is the most populous city of, France)<|>(Eiffel Tower, is a, landmark)<|>(Eiffel Tower, is in, Paris)\n"
     ]
    }
   ],
   "source": [
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7532f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' (Paris, is the capital of, France)', '(Paris, is the most populous city of, France)', '(Eiffel Tower, is a, landmark)', '(Eiffel Tower, is in, Paris)']\n"
     ]
    }
   ],
   "source": [
    "# Parse the generated triplets and create a list\n",
    "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "\n",
    "# Print the extracted relation triplets\n",
    "print(triples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d306c49",
   "metadata": {},
   "source": [
    "### 2. Knowledge Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6ce6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c17b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets):\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(',')\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "    return G\n",
    "\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph):\n",
    "    pyvis_graph = Network(notebook=True)\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48317589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "output/knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"output/knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x175a695a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth('discrete')\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show('output/knowledge_graph.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46163f99",
   "metadata": {},
   "source": [
    "**Note:** LangChain also offers the `GraphIndexCreator` class, which automates the extraction of relation triplets and is seamlessly integrated with question-answering chains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7832d",
   "metadata": {},
   "source": [
    "### 3. Additional Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9b712",
   "metadata": {},
   "source": [
    "- [Building a Knowledge Base from Texts: a Full Practical Example](https://medium.com/nlplanet/building-a-knowledge-base-from-texts-a-full-practical-example-8dbbffb912fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca01a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
