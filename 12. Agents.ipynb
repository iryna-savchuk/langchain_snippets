{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "The agents are intelligent entities and components interacting with the language model and other tools to fulfill a task. They have the capability to select the appropriate tools from a given list or formulate a plan and incorporate suitable tools at each step to get the job done. \n",
    "\n",
    "* [1. What are Agents](#what)\n",
    "    * [1.1. \"Content Generator\"- Writing a short science fiction story based on a given prompt](#generator)\n",
    "    * [1.2. \"Reasoning Engine\" - Answering Questions using Google Search and Math tool](#reasoning)\n",
    "* [2. Autonomous Agents (AutoGPT and BabyAGI)](#autonomous)\n",
    "* [3. Using AutoGPT with LangChain](#AutoGPT)\n",
    "* [4. Agent Simulation Projects: CAMEL and Generative Agents](#simulation)\n",
    "* [5. \"Plan and Execute\" framework](#plan_and_execute)\n",
    "* [6. Current Insights and Trends of Agents](#curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY, GOOGLE_API_KEY, GOOGLE_CSE_ID\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a18de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain==0.0.208 deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d6c3b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"what\">\n",
    "    \n",
    "## 1. What are Agents\n",
    "    \n",
    "</a>\n",
    "\n",
    "Agents - intelligent systems that utilize LLMs to determine actions and facilitate complex tasks. In the context of LLMs, agents are used to decide the course of action and the sequence of these actions. These actions can either be the utilization of a tool, observing its output, or offering a response to the user. \n",
    "\n",
    "- **Tool**: A function that performs a specific task. It can be a Google Search, a Database lookup, a Python REPL, or other chains. A tool's interface is typically a function that takes a string as an input and returns a string as an output.\n",
    "- **Language Learning Model**: The language model that powers the agent.\n",
    "- **Agent**: The agent to use, identified by a string that references a supported agent class. Itâ€™s what orchestrates the LLM and the tools. \n",
    "\n",
    "Agents in LangChain are of two categories:\n",
    "- **\"Action Agents\"**: typically used for straightforward tasks - they determine and execute a single action. \n",
    "- **\"Plan-and-Execute Agents\"**: first devise a plan comprising multiple actions and then execute each action sequentially. They are more suited for complex or long-running tasks as they help maintain focus on long-term objectives. (Be caucious - they might also lead to more calls and higher latency)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1532c",
   "metadata": {},
   "source": [
    "Workflow of Action Agents:\n",
    "1. The agent receives user input.\n",
    "2. It decides which tool to use (if any) and determines its input.\n",
    "3. The chosen tool is called with the provided input, and an observation (the output of the tool) is recorded.\n",
    "4. The history of the tool, tool input, and observation are relayed back to the agent, which then decides the next step.\n",
    "5. This process is repeated until the agent no longer needs to use a tool, at which point it directly responds to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740922ad",
   "metadata": {},
   "source": [
    "Workflow when the agent functions as a \"reasoning engine\":\n",
    "\n",
    "1. Query Processing: The agent receives a query and identifies distinct tasks within this query;\n",
    "2. Tool Utilization: The agent uses tools  - for example, \"google-search\" tool to answer the part of the query where necessary. The agent isn't creating this information; it's pulling the data from an external source.\n",
    "3. Information Processing: Again, the agent isn't creating new information. Instead, it's processing the data it has gathered. For example, it can use the \"llm-math\" tool to perform a sum reliably.\n",
    "4. Synthesis and Response: After gathering and processing the information, the agent synthesizes it into a coherent response that answers the original query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2cb8e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "In the context of LangChain, the term \"agents\" pertains to the concept of employing a language model as a <b>reasoning mechanism</b> and linking it with the key element - a tool. Tools are instrumental in connecting the language model with other sources of data or computation, including search engines, APIs, and other data repositories. Tools can also execute actions (like running code or modifying files) and observe the results, subsequently informing the language model's decision-making process.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02aeba0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"generator\">\n",
    "    \n",
    "### 1.1. \"Content Generator\"- Writing a short science fiction story based on a given prompt\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf542926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a tool to help me generate a story\n",
      "Action: Science Fiction Writer\n",
      "Action Input: Generate a story about interstellar explorers\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m.\n",
      "\n",
      "The year was 2120 and the human race had finally achieved interstellar travel. After decades of research and development, a team of brave explorers had been assembled to embark on a mission to explore the unknown reaches of the universe.\n",
      "\n",
      "The team was led by Captain John Smith, a veteran of many space missions. He was joined by a diverse group of scientists, engineers, and adventurers, all eager to explore the unknown.\n",
      "\n",
      "The team's first destination was a distant star system known as Alpha Centauri. After months of travel, they arrived at the system and began to explore the planets and moons in the vicinity.\n",
      "\n",
      "The team discovered a number of strange and fascinating phenomena, from strange alien life forms to mysterious energy fields. They also encountered a number of hostile forces, from hostile aliens to powerful robotic forces.\n",
      "\n",
      "The team eventually made it back to Earth with a wealth of knowledge and data about the universe. They had made a number of important discoveries, and their mission had been a success.\n",
      "\n",
      "The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The interstellar explorers had opened up a new era of exploration and discovery, and the human race was now ready to explore the stars.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"You're a renowned science fiction writer. {query}\"\n",
    ")\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Science Fiction Writer',\n",
    "        func=llm_chain.run,\n",
    "        description='Use this tool for generating science fiction stories. Input should be a command about generating specific types of stories.'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initializing an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Testing the agent with the new prompt\n",
    "response = agent.run(\"Compose an epic science fiction saga about interstellar explorers\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4bb4db",
   "metadata": {},
   "source": [
    "**NOTE**: LLM's understanding comes from its training data: it was trained on a diverse range of texts, so in this case its responses are generated based on patterns learned during training, not from a specific knowledge database. (Using LLM as a content creator can sometimes result in \"hallucinations\" or inaccuracies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00122ed2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"reasoning\">\n",
    "    \n",
    "### 1.2. \"Reasoning Engine\" - Answering Questions using Google Search and Math tool\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d866d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the number of goals scored in the 2018 soccer world cup\n",
      "Action: google_search\n",
      "Action Input: number of goals scored in the 2018 soccer world cup\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThis was three more goals than the previous tournament in 2018. Goals galore. The highest ever goals to game ratio was set during the 1954 World Cup inÂ ... Jan 31, 2020 ... A total of 169 goals were scored at the group and knockout stages of the FIFA World Cup held in Russia from the 14th of June to the 15th of JulyÂ ... 3 days ago ... This number can be attributed to some unusually high-scoring games, which included Austria 7 Switzerland 5 and Hungary 9 South Korea 0. TheÂ ... Number of goals scored in the matches played between the teams in question;; Fair play points in all group matches (only one deduction could be applied to aÂ ... France were crowned champions for the second time in history and for the first since they were hosts in 1998 after defeating Croatia 4-2 in what will go down asÂ ... The aim of this study was to elucidate pattern of attacking actions leading up to goal scoring during the 14 FIFA World Cups from 1966 to 2018. 2018 FIFA World Cup Russiaâ„¢. Back to FIFA+ Â· Match Centre Â· Teams. France. Winner. 7. Matches played. 14. Goals. 1.7. Goal Average. 12. Yellow CardsÂ ... Nov 20, 2022 ... If two teams share the same number of points and goal differential, the next criteria to determine ranking is number of goals scored in allÂ ... 0 Â· Luka MODRIC Â· Players Â· Top Scorers. Dec 18, 2022 ... Lionel Messi has scored 13 goals in 26 matches at the FIFA World Cup, spanning five editions (2006, 2010, 2014, 2018 and 2022).\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the number of goals scored in the 2018 soccer world cup\n",
      "Action: Calculator\n",
      "Action Input: 1000 + 169\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1169\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The result of 1000 plus the number of goals scored in the soccer world cup in 2018 is 1169.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The result of 1000 plus the number of goals scored in the soccer world cup in 2018 is 1169.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Loading the language model to control the agent\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Loading some tools to use. The llm-math tool uses an LLM, so we pass that in.\n",
    "tools = load_tools([\"google-search\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Initializing an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# Testing the agent\n",
    "query = \"What's the result of 1000 plus the number of goals scored in the soccer world cup in 2018?\"\n",
    "response = agent.run(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef6e60c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"autonomous\">\n",
    "    \n",
    "## 2. Autonomous Agents (AutoGPT and BabyAGI)\n",
    "    \n",
    "</a>\n",
    "\n",
    "Autonomous agents are AI systems designed to carry out tasks without needing constant human guidance. These agents are making waves due to their ability to work independently to achieve a specific objective. \n",
    "\n",
    "**AutoGPT** is an open-source initiative which employs GPT-4 to sift through the internet in a structured manner, formulate subtasks, and initiate new agents. AutoGPT can understand the overall goal, break it down into subtasks, execute those tasks, and dynamically adjust its actions based on the ongoing context.\n",
    "\n",
    "The initial conception of AutoGPT was as a general autonomous agent capable of doing anything. However, the wide breadth of application seemed to dilute its effectiveness and, as a result, a shift has been observed in the AutoGPT space, with developers starting to build specialized agents. These agents are designed to perform specific tasks effectively and efficiently, making them more practically useful. \n",
    "\n",
    "\n",
    "\n",
    "**BabyAGI** functions similarly - via the integration of GPT-4, a vector store, and LangChain. It creates tasks based on prior outcomes and a set goal. BabyAGI operates in a loop that revolves around four main sub-agents: the Execution Agent, the Task Creation Agent, the Prioritization Agent, and the Context Agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eecb0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install faiss-cpu\n",
    "# !pip install langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7532f110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Code Example of Using BabyAGI\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "\n",
    "# Define the embedding model\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Initialize the vectorstore\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05c86ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "1: Make a todo list\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "1. Research the best time to visit the Grand Canyon\n",
      "2. Book flights to the Grand Canyon\n",
      "3. Book a hotel near the Grand Canyon\n",
      "4. Research the best activities to do at the Grand Canyon\n",
      "5. Make a list of items to pack for the trip\n",
      "6. Make a budget for the trip\n",
      "7. Make a list of places to eat near the Grand Canyon\n",
      "8. Make a list of souvenirs to buy at the Grand Canyon\n",
      "9. Make a list of places to visit near the Grand Canyon\n",
      "10. Make a list of emergency contacts to have on hand during the trip\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research the best way to get to the Grand Canyon from the airport\n",
      "3: Research the best way to get around the Grand Canyon\n",
      "4: Research the best places to take pictures at the Grand Canyon\n",
      "5: Research the best places to go hiking at the Grand Canyon\n",
      "6: Research the best places to go camping at the Grand Canyon\n",
      "7: Research the best places to go sightseeing at the Grand Canyon\n",
      "8: Research the best places to go fishing at the Grand Canyon\n",
      "9: Research the best places to go horseback riding at the Grand Canyon\n",
      "10: Research the best places to go rafting at the Grand Canyon\n",
      "11: Research the cost of activities at the Grand Canyon\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "2: Research the best way to get to the Grand Canyon from the airport\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research the best way to get to the Grand Canyon from the airport. I will look into the different transportation options available, such as car rental, public transportation, and shuttle services. I will also compare the cost and convenience of each option. Additionally, I will research the best time of year to visit the Grand Canyon and the best places to stay near the Grand Canyon.\n",
      "\u001b[95m\u001b[1m\n",
      "*****TASK LIST*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research the cost of lodging near the Grand Canyon,\n",
      "4: Research the cost of food near the Grand Canyon,\n",
      "5: Research the cost of activities at the Grand Canyon,\n",
      "6: Research the best places to take pictures at the Grand Canyon,\n",
      "7: Research the best places to go sightseeing at the Grand Canyon,\n",
      "8: Research the best places to go fishing at the Grand Canyon,\n",
      "9: Research the best places to go horseback riding at the Grand Canyon,\n",
      "10: Research the best places to go rafting at the Grand Canyon,\n",
      "11: Research the best way to get around the Grand Canyon,\n",
      "12: Research the best places to go hiking at the Grand Canyon,\n",
      "13: Research the best places to go camping at the Grand Canyon,\n",
      "14: Research the best time of year to visit the Grand Canyon,\n",
      "15: Research the safety precautions to take when visiting the Grand Canyon.\n",
      "\u001b[92m\u001b[1m\n",
      "*****NEXT TASK*****\n",
      "\u001b[0m\u001b[0m\n",
      "3: Research the cost of lodging near the Grand Canyon,\n",
      "\u001b[93m\u001b[1m\n",
      "*****TASK RESULT*****\n",
      "\u001b[0m\u001b[0m\n",
      "\n",
      "\n",
      "I will research the cost of lodging near the Grand Canyon. I will look for hotels, motels, and other accommodations in the area and compare prices. I will also look for any discounts or special offers that may be available.\n",
      "\u001b[91m\u001b[1m\n",
      "*****TASK ENDING*****\n",
      "\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "# from langchain.experimental import BabyAGI\n",
    "from langchain_experimental.autonomous_agents import BabyAGI\n",
    "\n",
    "# Setting the goal\n",
    "goal = \"Plan a trip to the Grand Canyon\"\n",
    "\n",
    "# Creating the BabyAGI agent (If max_iterations is None, the agent may go on forever if stuck in loops)\n",
    "baby_agi = BabyAGI.from_llm(\n",
    "    llm=OpenAI(model=\"text-davinci-003\", temperature=0),\n",
    "    vectorstore=vectorstore,\n",
    "    verbose=False,\n",
    "    max_iterations=3\n",
    ")\n",
    "\n",
    "response = baby_agi({\"objective\": goal})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad9e59",
   "metadata": {},
   "source": [
    "This output reflects the systematic way in which the BabyAGI model approaches tasks: it begins by outlining the tasks, making a to-do list regarding a trip to the Grand Canyon, then it proceeds to complete each task one by one. For each task, it not only lists out the information gained through research but also offers a plan of action or what steps it would take to accomplish the task. The agent also dynamically updates its task list based on new information or steps necessary to accomplish broader tasks, like researching the best ways to get to the Grand Canyon, then breaking it down into more specific sub-tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec33e72",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"AutoGPT\">\n",
    "    \n",
    "## 3. Using AutoGPT with LangChain\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2384ba6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e70e4d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"simulation\">\n",
    "    \n",
    "## 4. Agent Simulation Projects: CAMEL and Generative Agents\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0e74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3369964",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"plan_and_execute\">\n",
    "    \n",
    "## 5. \"Plan and Execute\" framework\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df491c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058e24ca",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"curr\">\n",
    "    \n",
    "## 6. Current Insights and Trends of Agents\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f9c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
