{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# LLMs vs Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c2b6b",
   "metadata": {},
   "source": [
    "**LLMs** (such as GPT-3, Bloom, PaLM, and Aurora genAI) take a text string as input and return a text string as output. They are trained on language modeling tasks and can generate human-like text, perform complex reasoning, and even write code.\n",
    "\n",
    "**Chat Models** (such as ChatGPT) take a list of messages as input and return an AIMessageCopy. They typically use LLMs as their underlying technology, but their APIs are more structured. Chat Models are designed to remember previous exchanges with the user in a session and use that context to generate more relevant responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dd1ba",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d680bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  input_variables=[\"product\"],\n",
    "  template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7532f110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wireless Audio Solutions\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"wireless headphones\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc508a6",
   "metadata": {},
   "source": [
    "### Chat Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07065bd2",
   "metadata": {},
   "source": [
    "Types of messages used in LangChain chat models: \n",
    "- SystemMessageCopy \n",
    "- HumanMessageCopy \n",
    "- AIMessageCopy\n",
    "\n",
    "**SystemMessage**: provide initial instructions, context, or data for the AI model. They set the objectives the AI should follow and can help in controlling the AI's behavior. System messages are not user inputs but rather guidelines for the AI to operate within. They could include instructions, notifications, or error messages.\n",
    "\n",
    "**HumanMessage:** come from the user and represent their input to the AI model. The AI model is expected to respond to these messages. In LangChain, you can customize the human prefix (e.g., \"User\") in the conversation summary to change how the human input is represented.\n",
    "\n",
    "**AIMessage:** represent the AI's responses to human input. Like HumanMessage, it is possible to customize the AI prefix (e.g., \"AI Assistant\" or \"AI\") in the conversation summary to change how the AI's responses are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e388e7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example of using ChatOpenAI with a HumanMessage -\n",
    "# a chatbot that can translate an English sentence into French\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "  HumanMessage,\n",
    "  SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de079a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generations=[[ChatGeneration(text=\"J'adore la programmation.\", generation_info=None, message=AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, example=False))], [ChatGeneration(text='I like programming.', generation_info=None, message=AIMessage(content='I like programming.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 65, 'completion_tokens': 12, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo'} run=RunInfo(run_id=UUID('d99571e6-ee3b-4669-994d-4813a6037586'))\n"
     ]
    }
   ],
   "source": [
    "# Gnerating completions for multiple sets of messages using the \"generate\" method\n",
    "\n",
    "batch_messages = [\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: I love programming.\")\n",
    "  ],\n",
    "  [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates French to English.\"),\n",
    "    HumanMessage(content=\"Translate the following sentence: J'aime la programmation.\")\n",
    "  ],\n",
    "]\n",
    "\n",
    "print( chat.generate(batch_messages) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db1bd6",
   "metadata": {},
   "source": [
    "**Useful Resources:**\n",
    "- [A Complete Guide to LangChain: Building Powerful Applications with Large Language Models](https://notes.aimodels.fyi/a-complete-guide-to-langchain-building-powerful-applications-with-large-language-models/)\n",
    "- [ChatGPT and the Large Language Models (LLMs)](https://medium.com/chatgpt-learning-asia/chatgpt-and-the-large-language-models-llms-2b4b1f6e9962)\n",
    "- [Emergent properties of Large Language Models (LLMs) including ChatGPT](https://www.thoughtspot.com/data-trends/ai/large-language-models-vs-chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17b45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
