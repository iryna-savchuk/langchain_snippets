{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# LLM Memory\n",
    "\n",
    "In chat applications, retaining information from previous interactions is essential to maintain a consistent conversation flow. Let's explore when and how to use different types of memory. \n",
    "\n",
    "* [1. Monitoring Message History](#monitoring)\n",
    "    * [1.1. ConversationChain](#conversation)\n",
    "    * [1.2. ConversationBufferMemory](#buffer)\n",
    "* [2. Memory Types in LangChain](#memory_types)\n",
    "* [3. Chat with a GitHub Repository](#github)\n",
    "* [4. QA Chatbot over Documents with Sources](#with_sources)\n",
    "* [5. QA on Financial Data](#financial)\n",
    "* [6. QA on Any Data](#any)\n",
    "* [7. Additional Sources](#sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d6c3b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"monitoring\">\n",
    "    \n",
    "## 1. Monitoring Message History\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb166a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"conversation\">\n",
    "    \n",
    "### 1.1. ConversationChain\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a54314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hi there! It's nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"Hi there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d755e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:  Extra memory should be used when you need to store more data than the amount of memory your device has available. For example, if you are running a program that requires a lot of data to be stored, you may need to add extra memory to your device in order to run the program efficiently.\n",
      "Human: There are various types of memory in Langchain. When to use which type?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:  Extra memory should be used when you need to store more data than the amount of memory your device has available. For example, if you are running a program that requires a lot of data to be stored, you may need to add extra memory to your device in order to run the program efficiently.\n",
      "Human: There are various types of memory in Langchain. When to use which type?\n",
      "AI:  Different types of memory in Langchain are used for different purposes. For example, RAM is used for short-term storage of data, while ROM is used for long-term storage of data. Flash memory is used for storing data that needs to be accessed quickly, while EEPROM is used for storing data that needs to be retained even when the power is turned off. Depending on the type of data you need to store, you should choose the appropriate type of memory.\n",
      "Human: Do you remember what was our first message?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Yes, our first message was \"Hi there! It's nice to meet you. How can I help you today?\"\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input=\"In what scenarios extra memory should be used?\")\n",
    "output = conversation.predict(input=\"There are various types of memory in Langchain. When to use which type?\")\n",
    "output = conversation.predict(input=\"Do you remember what was our first message?\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e684383",
   "metadata": {},
   "source": [
    "As can be noticed from the “Current Conversation” section of the output, the model have access to all the previous messages. It can also remember what the initial message were after 3 questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7f773",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"buffer\">\n",
    "    \n",
    "### 1.2. ConversationBufferMemory\n",
    "    \n",
    "</a>\n",
    "\n",
    "To provide a history of messages (keep context), the `ConversationChain` uses the `ConversationBufferMemory` class by default. This memory can save the previous conversations in form of variables. The class accepts the `return_messages` argument which is helpful for dealing with chat models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61804459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi there!', additional_kwargs={}, example=False), AIMessage(content=\"Hi there! It's nice to meet you. How can I help you today?\", additional_kwargs={}, example=False)]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.save_context({\"input\": \"hi there!\"}, {\"output\": \"Hi there! It's nice to meet you. How can I help you today?\"})\n",
    "\n",
    "print( memory.load_memory_variables({}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2213bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative code, which will automatically call the .save_context() object after each interaction\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85c0547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "AI: What did the elephant say to the naked man? \"How do you breathe through that tiny thing?\"\n",
      "\n",
      "AI: The author of the Harry Potter series is J.K. Rowling.\n",
      "\n",
      "AI: The joke I told you earlier was \"What did the elephant say to the naked man? 'How do you breathe through that tiny thing?'\"\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "# Usage of \"ConversationChain\" and \"ConversationBufferMemory\"\n",
    "from langchain import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "print( conversation.predict(input=\"Tell me a joke about elephants\") )\n",
    "print( conversation.predict(input=\"Who is the author of the Harry Potter series?\") )\n",
    "print( conversation.predict(input=\"What was the joke you told me earlier?\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136a22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a human and an AI.\n",
      "Human: Tell me about the history of the Internet.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Tell me about the history of the Internet.', 'history': [HumanMessage(content='Tell me about the history of the Internet.', additional_kwargs={}, example=False), AIMessage(content='\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.', additional_kwargs={}, example=False)], 'response': '\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.'}\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "# Usage of \"ConversationChain\" and \"ConversationBufferMemory\"\n",
    "from langchain import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=True)\n",
    "\n",
    "# Start with general question\n",
    "user_message = \"Tell me about the history of the Internet.\"\n",
    "response = conversation(user_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5663ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a human and an AI.\n",
      "Human: Tell me about the history of the Internet.\n",
      "AI: \n",
      "\n",
      "AI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.\n",
      "Human: Who are some important figures in its development?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who are some important figures in its development?', 'history': [HumanMessage(content='Tell me about the history of the Internet.', additional_kwargs={}, example=False), AIMessage(content='\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.', additional_kwargs={}, example=False), HumanMessage(content='Who are some important figures in its development?', additional_kwargs={}, example=False), AIMessage(content='\\nAI:\\n\\nSome of the most important figures in the development of the Internet include Vint Cerf and Bob Kahn, who are credited with creating the TCP/IP protocol, which is the foundation of the modern Internet. Other important figures include Tim Berners-Lee, who created the World Wide Web, and Marc Andreessen, who created the first web browser. Additionally, many other people have contributed to the development of the Internet, including computer scientists, engineers, and entrepreneurs.', additional_kwargs={}, example=False)], 'response': '\\nAI:\\n\\nSome of the most important figures in the development of the Internet include Vint Cerf and Bob Kahn, who are credited with creating the TCP/IP protocol, which is the foundation of the modern Internet. Other important figures include Tim Berners-Lee, who created the World Wide Web, and Marc Andreessen, who created the first web browser. Additionally, many other people have contributed to the development of the Internet, including computer scientists, engineers, and entrepreneurs.'}\n"
     ]
    }
   ],
   "source": [
    "# User sends another message\n",
    "user_message = \"Who are some important figures in its development?\"\n",
    "response = conversation(user_message)\n",
    "print(response)  # Chatbot responds, recalling the previous topic and interpriting \"its\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9566c25",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"memory_types\">\n",
    "    \n",
    "## 2. Memory Types in LangChain\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71b6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5096b3a",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"github\">\n",
    "    \n",
    "## 3. Chat with a GitHub Repository\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d53d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9a6b474",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"with_sources\">\n",
    "    \n",
    "## 4. QA Chatbot over Documents with Sources\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840726a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ac0149e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"financial\">\n",
    "    \n",
    "## 5. QA on Financial Data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a7b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63600ac7",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"any\">\n",
    "    \n",
    "## 6. QA on Any Data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f41e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b704e5d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"sources\">\n",
    "    \n",
    "## 7. Additional Sources\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e12d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
