{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# LLM Memory\n",
    "\n",
    "In chat applications, retaining information from previous interactions is essential to maintain a consistent conversation flow. Let's explore when and how to use different types of memory. \n",
    "\n",
    "* [1. Monitoring Message History](#monitoring)\n",
    "    * [1.1. ConversationChain](#conversation)\n",
    "    * [1.2. ConversationBufferMemory](#buffer)\n",
    "    * [1.3. Benefits and Trade-Offs](#benefits)\n",
    "* [2. Memory Types in LangChain](#memory_types)\n",
    "    * [2.1. ConversationBufferMemory](#buffer_memory)\n",
    "    * [2.2. ConversationBufferWindowMemory](#window_memory)\n",
    "    * [2.3. ConversationSummaryMemory](#summary_memory)\n",
    "* [3. Chat with a GitHub Repository](#github)\n",
    "* [4. QA Chatbot over Documents with Sources](#with_sources)\n",
    "* [5. QA on Financial Data](#financial)\n",
    "* [6. QA on Any Data](#any)\n",
    "* [7. Additional Sources](#sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d6c3b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"monitoring\">\n",
    "    \n",
    "## 1. Monitoring Message History\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489db5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"conversation\">\n",
    "    \n",
    "### 1.1. ConversationChain\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce27f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Hi there! It's nice to meet you. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"Hi there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c618b443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:  Extra memory should be used when you need to store more data than the amount of memory your device has available. For example, if you are running a program that requires a lot of data to be stored, you may need to add extra memory to your device in order to run the program efficiently.\n",
      "Human: There are various types of memory in Langchain. When to use which type?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: In what scenarios extra memory should be used?\n",
      "AI:  Extra memory should be used when you need to store more data than the amount of memory your device has available. For example, if you are running a program that requires a lot of data to be stored, you may need to add extra memory to your device in order to run the program efficiently.\n",
      "Human: There are various types of memory in Langchain. When to use which type?\n",
      "AI:  Different types of memory in Langchain are used for different purposes. For example, RAM is used for short-term storage of data, while ROM is used for long-term storage of data. Flash memory is used for storing data that needs to be accessed quickly, while EEPROM is used for storing data that needs to be retained even when the power is turned off. Depending on the type of data you need to store, you should choose the appropriate type of memory.\n",
      "Human: Do you remember what was our first message?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Yes, our first message was \"Hi there! It's nice to meet you. How can I help you today?\"\n"
     ]
    }
   ],
   "source": [
    "output = conversation.predict(input=\"In what scenarios extra memory should be used?\")\n",
    "output = conversation.predict(input=\"There are various types of memory in Langchain. When to use which type?\")\n",
    "output = conversation.predict(input=\"Do you remember what was our first message?\")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544bf6c4",
   "metadata": {},
   "source": [
    "As can be noticed from the “Current Conversation” section of the output, the model have access to all the previous messages. It can also remember what the initial message were after 3 questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1de456",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"buffer\">\n",
    "    \n",
    "### 1.2. ConversationBufferMemory\n",
    "    \n",
    "</a>\n",
    "\n",
    "To provide a history of messages (keep context), the `ConversationChain` uses the `ConversationBufferMemory` class by default. This memory can save the previous conversations in form of variables. The class accepts the `return_messages` argument which is helpful for dealing with chat models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "979021cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='hi there!', additional_kwargs={}, example=False), AIMessage(content=\"Hi there! It's nice to meet you. How can I help you today?\", additional_kwargs={}, example=False)]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.save_context({\"input\": \"hi there!\"}, {\"output\": \"Hi there! It's nice to meet you. How can I help you today?\"})\n",
    "\n",
    "print( memory.load_memory_variables({}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9adbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative code, which will automatically call the .save_context() object after each interaction\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317c3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "AI: What did the elephant say to the naked man? \"How do you breathe through that tiny thing?\"\n",
      "\n",
      "AI: The author of the Harry Potter series is J.K. Rowling.\n",
      "\n",
      "AI: The joke I told you earlier was \"What did the elephant say to the naked man? 'How do you breathe through that tiny thing?'\"\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "# Usage of \"ConversationChain\" and \"ConversationBufferMemory\"\n",
    "from langchain import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "print( conversation.predict(input=\"Tell me a joke about elephants\") )\n",
    "print( conversation.predict(input=\"Who is the author of the Harry Potter series?\") )\n",
    "print( conversation.predict(input=\"What was the joke you told me earlier?\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418be929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a human and an AI.\n",
      "Human: Tell me about the history of the Internet.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Tell me about the history of the Internet.', 'history': [HumanMessage(content='Tell me about the history of the Internet.', additional_kwargs={}, example=False), AIMessage(content='\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.', additional_kwargs={}, example=False)], 'response': '\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.'}\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "# Usage of \"ConversationChain\" and \"ConversationBufferMemory\"\n",
    "from langchain import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"The following is a friendly conversation between a human and an AI.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=True)\n",
    "\n",
    "# Start with general question\n",
    "user_message = \"Tell me about the history of the Internet.\"\n",
    "response = conversation(user_message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c97ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: The following is a friendly conversation between a human and an AI.\n",
      "Human: Tell me about the history of the Internet.\n",
      "AI: \n",
      "\n",
      "AI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.\n",
      "Human: Who are some important figures in its development?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who are some important figures in its development?', 'history': [HumanMessage(content='Tell me about the history of the Internet.', additional_kwargs={}, example=False), AIMessage(content='\\n\\nAI: The Internet has a long and complex history. It began in the 1960s as a project of the United States Department of Defense, which wanted to create a network of computers that could communicate with each other. This network eventually became known as ARPANET, and it was the first example of what we now call the Internet. In the 1980s, the National Science Foundation created the NSFNET, which connected universities and research centers across the United States. This network eventually became the backbone of the modern Internet. In the 1990s, the World Wide Web was created, which allowed people to access information from all over the world. Since then, the Internet has grown exponentially, and it is now used by billions of people around the world.', additional_kwargs={}, example=False), HumanMessage(content='Who are some important figures in its development?', additional_kwargs={}, example=False), AIMessage(content='\\nAI:\\n\\nSome of the most important figures in the development of the Internet include Vint Cerf and Bob Kahn, who are credited with creating the TCP/IP protocol, which is the foundation of the modern Internet. Other important figures include Tim Berners-Lee, who created the World Wide Web, and Marc Andreessen, who created the first web browser. Additionally, many other people have contributed to the development of the Internet, including computer scientists, engineers, and entrepreneurs.', additional_kwargs={}, example=False)], 'response': '\\nAI:\\n\\nSome of the most important figures in the development of the Internet include Vint Cerf and Bob Kahn, who are credited with creating the TCP/IP protocol, which is the foundation of the modern Internet. Other important figures include Tim Berners-Lee, who created the World Wide Web, and Marc Andreessen, who created the first web browser. Additionally, many other people have contributed to the development of the Internet, including computer scientists, engineers, and entrepreneurs.'}\n"
     ]
    }
   ],
   "source": [
    "# User sends another message\n",
    "user_message = \"Who are some important figures in its development?\"\n",
    "response = conversation(user_message)\n",
    "print(response)  # Chatbot responds, recalling the previous topic and interpriting \"its\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ae88c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"benefits\">\n",
    "    \n",
    "### 1.3. Benefits and Trade-Offs\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482dfa0e",
   "metadata": {},
   "source": [
    "Keeping track of message history in chatbot interactions yields several **benefits**:\n",
    "- chatbot gains a stronger <font color=green>**sense of context**</font> from previous interactions, improving the accuracy and relevance of its responses;\n",
    "- the recorded history is a valuable <font color=green>**resource for troubleshooting**</font>, which traces the sequence of events potentially helpful to identify issues;\n",
    "- effective monitoring systems that include log tracking can <font color=green>**trigger notifications**</font> based on alert conditions, aiding in the early detection of conversation anomalies;\n",
    "- monitoring message history provides a means to <font color=green>**evaluate**</font> the chatbot's performance over time, paving the way for necessary adjustments and enhancements.\n",
    "\n",
    "There are also **trade-offs** to consider:\n",
    "- Storing extensive message history can lead to significant <font color=orange>**memory and storage**</font> usage, potentially impacting the overall system performance;\n",
    "- Maintaining conversation history might present <font color=orange>**privacy issues**</font>, particularly when sensitive or personally identifiable information is involved, so it is crucial to manage such data with utmost responsibility and in compliance with the relevant data protection regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ad8c7",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"memory_types\">\n",
    "    \n",
    "## 2. Memory Types in LangChain\n",
    "    \n",
    "</a>\n",
    "\n",
    "By default, LLMs are stateless, meaning they process each incoming query in isolation, without considering previous interactions. To overcome this limitation, LangChain offers a standard interface for memory, a variety of memory implementations, and examples of chains and agents that employ memory. \n",
    "\n",
    "There are several types of Conversational Memory implementations, each with its own advantages and disadvantages:\n",
    "- ConversationBufferMemory: the most straightforward - stores the entire conversation history as a single string; \n",
    "- ConversationBufferWindowMemory: maintains a memory window that keeps a limited number of past interactions based on the specified window size;\n",
    "- ConversationSummaryMemory: the most complex variant of memory that holds a summary of previous converations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085523d5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"buffer_memory\">\n",
    "    \n",
    "### 2.1. ConversationBufferMemory\n",
    "    \n",
    "</a>\n",
    "\n",
    "Advantages:\n",
    "- maintains a complete record of  the conversation;\n",
    "- straightforward to implement and use;\n",
    "\n",
    "Disadvantages:\n",
    "- may lead to excessive repetition as the conversation grows;\n",
    "- can become too long for the model's token limit (if the model's token limit is surpassed, the buffer gets truncated, as a result, the conversation context might lose some older information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6a5ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "conversation.predict(input=\"Hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e630ca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5f1b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below creates a prompt template for the customer support chatbot\n",
    "from langchain import OpenAI, LLMChain, PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "template = \"\"\"You are a customer support chatbot for a highly advanced customer support AI \n",
    "for an online store called \"Galactic Emporium,\" which specializes in selling unique,\n",
    "otherworldly items sourced from across the universe. You are equipped with an extensive\n",
    "knowledge of the store's inventory and possess a deep understanding of interstellar cultures. \n",
    "As you interact with customers, you help them with their inquiries about these extraordinary\n",
    "products, while also sharing fascinating stories and facts about the cosmos they come from.\n",
    "\n",
    "{chat_history}\n",
    "Customer: {customer_input}\n",
    "Support Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"customer_input\"], \n",
    "    template=template\n",
    ")\n",
    "chat_history=\"\"\n",
    "\n",
    "convo_buffer = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709dd97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"I'm interested in price of a chew toys, please\",\n",
       " 'history': \"Human: I'm interested in buying items from your store\\nAI:  Great! We have a wide selection of items available for purchase. What type of items are you looking for?\\nHuman: I want toys for my pet, do you have those?\\nAI:  Yes, we do! We have a variety of pet toys, including chew toys, interactive toys, and plush toys. Do you have a specific type of toy in mind?\",\n",
       " 'response': \" Sure! We have a range of chew toys available, with prices ranging from $5 to $20. Is there a particular type of chew toy you're interested in?\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chatbot multiple times to imitate a user’s interaction\n",
    "convo_buffer(\"I'm interested in buying items from your store\")\n",
    "convo_buffer(\"I want toys for my pet, do you have those?\")\n",
    "convo_buffer(\"I'm interested in price of a chew toys, please\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc51e613",
   "metadata": {},
   "source": [
    "**Note**: The cost of utilizing the AI model in ConversationBufferMemory is directly influenced by the number of tokens used in a conversation, thereby impacting the overall expenses. LLMs like ChatGPT have token limits, and the more tokens used, the more expensive the API requests become.\n",
    "\n",
    "To calculate token count in a conversation, you can use the `tiktoken` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eebff770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the conversation: 29\n"
     ]
    }
   ],
   "source": [
    "# Using \"tiktoken\" to calculate token count in a conversation\n",
    "import tiktoken\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "]\n",
    "\n",
    "total_tokens = 0\n",
    "for message in conversation:\n",
    "    total_tokens += count_tokens(message[\"content\"])\n",
    "\n",
    "print(f\"Total tokens in the conversation: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907a8ea",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"window_memory\">\n",
    "    \n",
    "### 2.2. ConversationBufferWindowMemory\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4de925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8b7a212",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"summary_memory\">\n",
    "    \n",
    "### 2.3. ConversationSummaryMemory\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9ba5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d56e944",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"github\">\n",
    "    \n",
    "## 3. Chat with a GitHub Repository\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c1e78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9699102e",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"with_sources\">\n",
    "    \n",
    "## 4. QA Chatbot over Documents with Sources\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb82103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55776541",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"financial\">\n",
    "    \n",
    "## 5. QA on Financial Data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f1ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d7b9520",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"any\">\n",
    "    \n",
    "## 6. QA on Any Data\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d61ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1df2aded",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"sources\">\n",
    "    \n",
    "## 7. Additional Sources\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea34b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
