{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac34004",
   "metadata": {},
   "source": [
    "## 1. The Power and Limitations of Large Language Models\n",
    "\n",
    "Large Language Models (LLMs) are trained to understand the distribution of words in a language, enabling them to **generate meaningful text** without memorizing specific data. However, their knowledge is limited to the training data, leading to potential fabrications when asked about information beyond their training period, known as **\"hallucination.\"**\n",
    "\n",
    "To address this issue, **retrievers** can be used alongside LLMs. Retrievers fetch information from trusted sources, and LLMs are prompted to rearrange the retrieved information without adding new details. LLMs like GPT-4 and Claude can handle large context window sizes, but an efficient retriever is needed to find the most relevant documents due to the cost of execution.\n",
    "\n",
    "Efficient retrievers are built using embedding models that map texts to vectors. These vectors are then stored in specialized databases called vector stores. This is where **Deep Lake** comes in: it provides a seamless way to store embeddings and their corresponding metadata. Deep Lake also enables hybrid searches on these embeddings and their attributes for efficient data retrieval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa83c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install deeplake\n",
    "#!pip install openai\n",
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253aa370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keys import ACTIVELOOP_TOKEN, OPENAI_API_KEY\n",
    "\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d741e8f5",
   "metadata": {},
   "source": [
    "## 2. The LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3e8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the LLM wrapper\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae214086",
   "metadata": {},
   "source": [
    "The temperature parameter in OpenAI models manages the randomness of the output.\n",
    "- 0: output is mostly predetermined and result is stable;\n",
    "- 1: output can be inconsistent and interesting, but isn't generally advised for most tasks;\n",
    "- between 0.70 and 0.90: offers a balance of reliability and creativity for creative tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5520ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GPT-3 model’s Davinci variant\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c73ebf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Jogging: Aim to jog for at least 30 minutes 3-4 times per week. Start at a slow pace and gradually increase your running speed and intensity as your endurance improves.\n",
      "\n",
      "2. Trail Running: Trail running improves coordination and balance. Aim to run 2-3 times per week on off-road trails. Start at a slow pace and gradually increase your speed and distance.\n",
      "\n",
      "3. Hill Sprinting: Hill sprinting is a great way to improve cardiovascular endurance and build leg strength. Sprint up a steep hill for 30 seconds and then walk or jog back down. Aim to do this 3-4 times per week.\n",
      "\n",
      "4. Swimming: Swimming is an excellent way to improve cardiovascular endurance and build upper body strength. Aim to swim for 30 minutes 3-4 times per week.\n",
      "\n",
      "5. Cycling: Cycling is a great way to build endurance. Aim to bike for 30 minutes 3-4 times a week. Start at an easy pace and gradually increase your speed and intensity as your endurance improves.\n",
      "\n",
      "6. Rowing: Rowing is an excellent cardiovascular exercise. Aim to row for 30 minutes 3-4 times a week. Start at an easy pace and gradually increase your speed and intensity as your\n"
     ]
    }
   ],
   "source": [
    "# Example of calling the initialized LLM\n",
    "text = \"Suggest a personalized workout routine for someone looking to improve cardiovascular endurance and prefers outdoor activities.\"\n",
    "\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabe26d1",
   "metadata": {},
   "source": [
    "## 3. The Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639973f",
   "metadata": {},
   "source": [
    "A chain is a combination of multiple individual components in a specific sequence. The most commonly used type of chain is the **LLMChain**, which consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser.\n",
    "\n",
    "The LLMChain works as follows:\n",
    "\n",
    "1. Takes input variable(s);\n",
    "2. Format the input variables into a prompt by using the PromptTemplate;\n",
    "3. Passes the formatted prompt to the model (LLM or ChatModel);\n",
    "4. Parses the output of the LLM into a final format, if an OutputParser is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e40d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a chain that generates a possible name for a company that produces a given product\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f7e4a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "EcoBottles.\n"
     ]
    }
   ],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "print(chain.run(\"eco-friendly water bottles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a57242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Brewed Moments.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"personalized tea cups\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092981f",
   "metadata": {},
   "source": [
    "## 4. The Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47c787",
   "metadata": {},
   "source": [
    "In LangChain, Memory refers to the mechanism that stores and manages the conversation history between a user and the AI. It helps maintain context and coherency throughout the interaction, enabling the AI to generate more relevant and accurate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23421cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Tell me about yourself.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Tell me about yourself.\n",
      "AI:  Hi there! I'm an AI created to help people with their daily tasks. I'm programmed to understand natural language and respond to questions and commands. I'm also able to learn from my interactions with people, so I'm constantly growing and improving. I'm excited to help you out!\n",
      "Human: What can you do?\n",
      "AI:  I can help you with a variety of tasks, such as scheduling appointments, setting reminders, and providing information. I'm also able to answer questions about topics like current events, sports, and entertainment. I'm always learning new things, so I'm sure I can help you with whatever you need.\n",
      "Human: How can you help me with data analysis?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I'm not familiar with data analysis, but I'm sure I can help you find the information you need. I can search the web for articles and resources related to data analysis, and I can also provide you with links to helpful websites.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory # a wrapper around ChatMessageHistory\n",
    "\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "conversation.predict(input=\"Tell me about yourself.\")\n",
    "\n",
    "# Continue the conversation\n",
    "conversation.predict(input=\"What can you do?\")\n",
    "conversation.predict(input=\"How can you help me with data analysis?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f373330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display the conversation:\n",
    "# print(conversation)            ### Careful: it displays the openai_api_key!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e8a17",
   "metadata": {},
   "source": [
    "## 5. Deep Lake VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48008f52",
   "metadata": {},
   "source": [
    "Deep Lake provides storage for embeddings and their corresponding metadata in the context of LLM apps. It enables hybrid searches on these embeddings and their attributes for efficient data retrieval. It also integrates with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730bada",
   "metadata": {},
   "source": [
    "### 5.1. Using Deep Lake as a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac706d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Instantiate the LLM and embeddings models\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Create documents\n",
    "texts = [\n",
    "    \"Napoleon Bonaparte was born in 15 August 1769\",\n",
    "    \"Louis XIV was born in 5 September 1638\"\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca74b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "The dataset is private so make sure you are logged in!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# Create Deep Lake dataset\n",
    "my_activeloop_org_id = \"iryna\" \n",
    "my_activeloop_dataset_name = \"langchain_course_from_zero_to_hero\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82f9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://iryna/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (2, 1536)  float32   None   \n",
      "    id        text      (2, 1)      str     None   \n",
      " metadata     json      (2, 1)      str     None   \n",
      "   text       text      (2, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1a4a8ff6-1614-11ee-bc41-12ee7aa5dbdc',\n",
       " '1a4a9190-1614-11ee-bc41-12ee7aa5dbdc']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add documents to the Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02900695",
   "metadata": {},
   "source": [
    "### 5.2. Creating an agent with a RetrievalQA chain as a tool to answer questions based on the given document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cddaf03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a RetrievalQA chain\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ce12114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an agent that uses the RetrievalQA chain as a tool\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6727a74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Napoleone was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Napoleone born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Napoleon Bonaparte was born on 15 August 1769.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Napoleon Bonaparte was born on 15 August 1769.\n"
     ]
    }
   ],
   "source": [
    "# Using the agent to ask a question\n",
    "response = agent.run(\"When was Napoleone born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e680331",
   "metadata": {},
   "source": [
    "### 5.3. Reloading an existing vector store and adding more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96c1e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://iryna/langchain_course_from_zero_to_hero already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://iryna/langchain_course_from_zero_to_hero', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      " embedding  embedding  (5, 1536)  float32   None   \n",
      "    id        text      (5, 1)      str     None   \n",
      " metadata     json      (5, 1)      str     None   \n",
      "   text       text      (5, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9252369a-1617-11ee-bc41-12ee7aa5dbdc',\n",
       " '92523898-1617-11ee-bc41-12ee7aa5dbdc',\n",
       " '92523906-1617-11ee-bc41-12ee7aa5dbdc']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the existing Deep Lake dataset and specify the embedding function\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)\n",
    "\n",
    "# Create new documents\n",
    "texts = [\n",
    "    \"Lady Gaga was born in 28 March 1986\",\n",
    "    \"Michael Jeffrey Jordan was born in 17 February 1963\",\n",
    "    \"Claude Monet was born on November 14, 1840.\"\n",
    "]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.create_documents(texts)\n",
    "\n",
    "# Add documents to our Deep Lake dataset\n",
    "db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ea90fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Recreate the previous agent and to ask new questions ##\n",
    "##########################################################\n",
    "\n",
    "# Instantiate the wrapper class for GPT3\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "# Create a retriever from the db\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=db.as_retriever()\n",
    ")\n",
    "\n",
    "# Instantiate a tool that uses the retriever\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Retrieval QA System\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Useful for answering questions.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Create an agent that uses the tool\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdfbec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Michael Jordan was born.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When was Michael Jordan born?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Michael Jordan was born on 17 February 1963.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Michael Jordan was born on 17 February 1963.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When was Michael Jordan born?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee543da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out when Claude Monet's birthday is.\n",
      "Action: Retrieval QA System\n",
      "Action Input: When is Claude Monet's birthday?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Claude Monet's birthday is November 14, 1840.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Claude Monet's birthday is November 14, 1840.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Claude Monet's birthday is November 14, 1840.\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\"When is birthday of Claude Monet?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73362d",
   "metadata": {},
   "source": [
    "## 6. Agents in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791467db",
   "metadata": {},
   "source": [
    "**Agents** are high-level components that use language models (LLMs) to determine which actions to take and in what order. An **action**: either using a tool and observing its output or returning it to the user. **Tools** are functions that perform specific duties, such as Google Search, database lookups, or Python REPL.\n",
    "\n",
    "Types of agents are available in LangChain:\n",
    "\n",
    "- The `zero-shot-react-description` agent uses the ReAct framework to decide which tool to employ based purely on the tool's description. It necessitates a description of each tool.\n",
    "- The `react-docstore` agent engages with a docstore through the ReAct framework. It needs two tools: a Search tool and a Lookup tool. The Search tool finds a document, and the Lookup tool searches for a term in the most recently discovered document.\n",
    "- The `self-ask-with-search` agent employs a single tool named Intermediate Answer, which is capable of looking up factual responses to queries. It is identical to the original self-ask with the search paper, where a Google search API was provided as the tool.\n",
    "- The `conversational-react-description` agent is designed for conversational situations. It uses the ReAct framework to select a tool and uses memory to remember past conversation interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf5ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keys import GOOGLE_API_KEY, GOOGLE_CSE_ID\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9a41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI \n",
    "\n",
    "from langchain.agents import AgentType \n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf2dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)  # temperature to 0 for the precise answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88855389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Google search wrapper\n",
    "search = GoogleSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63e30dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # a tool for performing Google searches\n",
    "    Tool( \n",
    "        name = \"google-search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to search google to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c9b5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "                         verbose=True,\n",
    "                         max_iterations=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91ab4787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about the Mars rover\n",
      "Action: google-search\n",
      "Action Input: \"latest news Mars rover\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. NASA's Curiosity rover is discovering odd rocks halfway into a region called the \"clay-bearing unit.\" ... This panorama of a location called \"Teal Ridge\" was ... Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Apr 28, 2023 ... Friday's news comes days after mission leaders acknowledged that the Zhurong rover has yet to wake up since going into hibernation for the ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for National Breaking News Alerts. Sep 16, 2022 ... Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars. Nasa Mars lander study reveals 'main source of heat' on Red Planet · NASA/ESA/A. Simon (Goddard Space Flight Center) and M.H. Wong.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest news about the Mars rover is that the mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. China's Mars rover has likely suffered excessive damage due to hibernation, and NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest news about the Mars rover?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2fd6a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the latest news about Ukraine counteroffensive\n",
      "Action: google-search\n",
      "Action Input: \"Ukraine counteroffensive\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m3 days ago ... The Ukrainian Army is encountering an array of challenges that has complicated the early stages of its counteroffensive, especially the ... 6 days ago ... While saying little, Putin has revealed that military failures are entirely at odds with his vision for the future, while several more ... 6 days ago ... The Ukrainian strategy in the counteroffensive is to strike south and drive a wedge through Russian occupied territory, dividing the Russian ... Jun 15, 2023 ... The counteroffensive is complicated by Ukraine's lack of air power. Kyiv has lobbied the West for months to supply F-16 fighter jets but they ... 6 days ago ... In its early phases, Ukraine's counteroffensive is having less success and Russian forces are showing more competence than western ... Jun 12, 2023 ... Ukrainian President Volodymyr Zelenskyy said Saturday that counteroffensive and defensive actions are underway against Russian forces, asserting ... 6 days ago ... These villages were liberated in Ukraine's grinding counteroffensive. They're little more than ruins. Jun 13, 2023 ... Ukraine news from June 10: Ukrainian president confirms counteroffensive operations under way against Russian forces. Published On 10 Jun 202310 ... Jun 5, 2023 ... Ukraine has been preparing for a counteroffensive against the Russian troops that invaded their country. \"Our goal has been to provide them with ... 2 days ago ... Ukraine “continues to move forward with a counteroffensive,” he said on NBC's “Meet the Press” on Sunday. “These are early days, but they haven' ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The latest update about Ukraine counteroffensive is that Ukrainian President Volodymyr Zelenskyy said Saturday that counteroffensive and defensive actions are underway against Russian forces, asserting that Ukraine is continuing to move forward with a counteroffensive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The latest update about Ukraine counteroffensive is that Ukrainian President Volodymyr Zelenskyy said Saturday that counteroffensive and defensive actions are underway against Russian forces, asserting that Ukraine is continuing to move forward with a counteroffensive.\n"
     ]
    }
   ],
   "source": [
    "response = agent(\"What's the latest update about Ukraine counteroffensive?\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f716c",
   "metadata": {},
   "source": [
    "## 7. Tools in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc5393",
   "metadata": {},
   "source": [
    "LangChain provides a variety of tools for agents to interact with the outside world. These tools can be used to create custom agents that perform various tasks: web searching, answering questions, or running Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8940b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5731603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a  LLMChain specifically for text summarization\n",
    "llm = OpenAI(model=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Write a summary of the following text: {query}\"\n",
    ")\n",
    "\n",
    "summarize_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8b94cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for finding information about recent events\"\n",
    "    ),\n",
    "    Tool(\n",
    "       name='Summarizer',\n",
    "       func=summarize_chain.run,\n",
    "       description='useful for summarizing texts'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6015f51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an agent that leverages two tools\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e677ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the latest news about the Mars rover and then summarize it.\n",
      "Action: Search\n",
      "Action Input: Latest news about the Mars rover\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mMars 2020 Perseverance Rover · The largest and most capable rover ever sent to Mars. ... Curiosity Rover · Measures Mars' atmosphere to understand its climate ... Dec 15, 2021 ... Mars Sample Return is going to have great stuff to choose from!” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER. The mission has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. Oct 19, 2022 ... NASA's Curiosity Mars rover used its Mast Camera, or Mastcam, to capture this panorama of a hill nicknamed ... Get the Latest JPL News. NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. Curiosity rover finds water-carved 'book' rock on Mars (photo) ... A book-shaped rock on Mars was likely carved by ancient water running through the area, ... Feb 8, 2023 ... “Mars' ancient climate had a wonderful complexity to it, much like Earth's.” Get the Latest JPL News. SUBSCRIBE TO THE NEWSLETTER ... Sep 16, 2022 ... Since July, NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars. Apr 25, 2023 ... China's Mars rover, which has been in longer-than-expected hibernation on the red planet since May 2022, has likely suffered excessive ... Mar 7, 2023 ... 27, helps provide scientists with information about the particle sizes within the clouds. Sign up for National Breaking News Alerts.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have a lot of information about the Mars rover, so I should use the summarizer to get a concise overview.\n",
      "Action: Summarizer\n",
      "Action Input: Mars 2020 Perseverance Rover is the largest and most capable rover ever sent to Mars. It measures Mars' atmosphere to understand its climate and has concluded that the solar-powered lander has run out of energy after more than four years on the Red Planet. NASA's Curiosity Mars rover used its Mast Camera to capture a panorama of a hill nicknamed \"Book Rock\" which was likely carved by ancient water running through the area. NASA's Mars 2020 Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration. China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022 and has likely suffered excessive damage. NASA's Perseverance rover has drilled and collected four slim cores of sedimentary rock, formed in what was once a lake on Mars.\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m It has also taken pictures of the Martian surface and analyzed the atmosphere to understand the climate. The rover is also equipped with a microphone to record the sounds of Mars, and a laser to vaporize rocks and analyze their composition. It will also collect samples of rock and soil for future study. \n",
      "\n",
      "NASA's Mars 2020 Perseverance rover is the largest and most capable rover ever sent to Mars. It has been on the Red Planet for more than four years and has used its Mast Camera to capture a panorama of a hill nicknamed \"Book Rock\". The rover is equipped with a microphone to record the sounds of Mars, a laser to vaporize rocks and analyze their composition, and has drilled and collected four slim cores of sedimentary rock. It has also taken pictures of the Martian surface and analyzed the atmosphere to understand the climate. China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022 and has likely suffered excessive damage. The Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: NASA's Mars 2020 Perseverance rover is the largest and most capable rover ever sent to Mars. It has been on the Red Planet for more than four years and has used its Mast Camera to capture a panorama of a hill nicknamed \"Book Rock\". The rover is equipped with a microphone to record the sounds of Mars, a laser to vaporize rocks and analyze their composition, and has drilled and collected four slim cores of sedimentary rock. It has also taken pictures of the Martian surface and analyzed the atmosphere to understand the climate. China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022 and has likely suffered excessive damage. The Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "NASA's Mars 2020 Perseverance rover is the largest and most capable rover ever sent to Mars. It has been on the Red Planet for more than four years and has used its Mast Camera to capture a panorama of a hill nicknamed \"Book Rock\". The rover is equipped with a microphone to record the sounds of Mars, a laser to vaporize rocks and analyze their composition, and has drilled and collected four slim cores of sedimentary rock. It has also taken pictures of the Martian surface and analyzed the atmosphere to understand the climate. China's Mars rover has been in longer-than-expected hibernation on the red planet since May 2022 and has likely suffered excessive damage. The Perseverance rover will look for signs of past microbial life, cache rock and soil samples, and prepare for future human exploration.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "response = agent(\"What's the latest news about the Mars rover? Then please summarize the results.\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e94e53d",
   "metadata": {},
   "source": [
    "LangChain provides a toolkit that integrates various functions to improve the functionality of conversational agents, for instance:\n",
    "- `SerpAPI`: an interface for the SerpAPI search engine, allowing the agent to perform robust online searches to pull in relevant data for a conversation or task.\n",
    "- `PythonREPLTool`: tool that enables the writing and execution of Python code within an agent. This opens up a wide range of possibilities for advanced computations and interactions within the conversation.\n",
    "- `custom tools`: allows adding more specialized capabilities to the LangChain conversational agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75064f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
