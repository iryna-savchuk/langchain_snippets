{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# Extending Texts (Blog Posts) with LangChain and Google Search \n",
    "\n",
    "STEPS:\n",
    "* [1. Setup](#setup)\n",
    "* [2. Generating Search Queries](#search)\n",
    "* [3. Getting Search Results](#results)\n",
    "* [4. Finding the Most Relevant Results](#relevant)\n",
    "* [5. Extending the Sentence](#extend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16687644",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"setup\">\n",
    "    \n",
    "## 1. Setup\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096bd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain==0.0.208 deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286323e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q newspaper3k==0.2.8 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from keys import OPENAI_API_KEY, GOOGLE_CSE_ID, GOOGLE_API_KEY\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_CSE_ID\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d6c3b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"search\">\n",
    "    \n",
    "## 2. Generating Search Queries\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f205ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
    "\n",
    "text_all = \"\"\" Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models. Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial. Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
    "\n",
    "text_to_change = \"\"\" Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09211e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\" You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
    "Write 3 queries as a bullet point list, prepending each line with -.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "#chat = ChatOpenAI(model_name=\"text-davinci-003\", temperature=0.9)\n",
    "chat = ChatOpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d668f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fffe029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- AI voice cloning software applications for speech synthesis\\n- Transformative nature of AI in elections, jobs, and security\\n- Implications of AI technology on various industries'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6395bb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI voice cloning software applications for speech synthesis', 'Transformative nature of AI in elections, jobs, and security', 'Implications of AI technology on various industries']\n"
     ]
    }
   ],
   "source": [
    "queries = [line[2:] for line in response.split(\"\\n\")]\n",
    "print(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ce5e2",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"results\">\n",
    "    \n",
    "## 3. Getting Search Results\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158b31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "import time\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "TOP_N_RESULTS = 5\n",
    "\n",
    "def top_n_results(query):\n",
    "    return search.results(query, TOP_N_RESULTS)\n",
    "\n",
    "tool = Tool(\n",
    "    name = \"Google Search\",\n",
    "    description=\"Search Google for recent results.\",\n",
    "    func=top_n_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f49e31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for query in queries:\n",
    "    results = tool.run(query)\n",
    "    all_results += results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8cd9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Economic potential of generative AI | McKinsey\n",
      "https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier\n",
      "Jun 14, 2023 ... Generative AI will have a significant impact across all industry sectors. Banking, high tech, and life sciences are among the industries ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if \"title\" in results[0]: # Sample\n",
    "    print(results[0][\"title\"])\n",
    "    print(results[0][\"link\"])\n",
    "    print(results[0][\"snippet\"])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be818fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b6a03",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"relevant\">\n",
    "    \n",
    "## 4. Finding the Most Relevant Results\n",
    "\n",
    "</a>\n",
    "\n",
    "The `all_results` variable holds 15 web addresses: 3 queries from ChatGPT x 5 top Google search results. However, it is not optimal to use all the contents as a context in our application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b3ad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages:  8\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "\n",
    "pages_content = []\n",
    "\n",
    "for result in all_results:\n",
    "    try:\n",
    "        article = newspaper.Article(result[\"link\"])\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        \n",
    "        if len(article.text) > 0:\n",
    "            pages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Number of pages: \", len(pages_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25c36706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  70\n"
     ]
    }
   ],
   "source": [
    "# Split the saved contents into smaller chunks \n",
    "# to ensure the articles do not exceed the model’s input length\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "\n",
    "docs = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
    "        docs.append(new_doc)\n",
    "\n",
    "print(\"Number of chunks: \", len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c3cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding docs and query\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "query_embedding = embeddings.embed_query(text_to_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73c6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cosine similarity to get the most relevant docs\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
    "    # convert the lists of vectors to numpy arrays\n",
    "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "    query_vector = np.array(query_vector)\n",
    "\n",
    "    # compute cosine similarities\n",
    "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "    # sort the vectors based on cosine similarity\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "    # retrieve the top K indices from the sorted list\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    return top_k_indices\n",
    "\n",
    "\n",
    "top_k = 3\n",
    "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
    "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c98fff",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"extend\">\n",
    "    \n",
    "## 5. Extending the Sentence\n",
    "\n",
    "</a>\n",
    "\n",
    "We can now define the prompt using the additional information from Google search. There are six input variables in the template:\n",
    "\n",
    "- `title`: the main article’s title;\n",
    "- `text_all`: the whole article we are working on;\n",
    "- `text_to_change`: the selected part of the article that requires expansion;\n",
    "- `doc_1`, `doc_2`, `doc_3`: close Google search results to include as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8351c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an exceptional copywriter and content creator.\n",
    "\n",
    "You're reading an article with the following title:\n",
    "----------------\n",
    "{title}\n",
    "----------------\n",
    "\n",
    "You've just read the following piece of text from that article.\n",
    "----------------\n",
    "{text_all}\n",
    "----------------\n",
    "\n",
    "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
    "----------------\n",
    "{text_to_change}\n",
    "----------------\n",
    "\n",
    "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
    "----------------\n",
    "{doc_1}\n",
    "----------------\n",
    "{doc_2}\n",
    "----------------\n",
    "{doc_3}\n",
    "----------------\n",
    "\n",
    "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
    "\"\"\"\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate(\n",
    "    prompt=PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
    "    )\n",
    ")\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed0b9315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text to Change:   Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
      "**********************\n",
      "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. This demonstration highlights the growing availability and sophistication of AI voice cloning technology. As seen with the controversy surrounding a vocal deepfake of Anthony Bourdain, voice clones are becoming more realistic and can be utilized in various applications. In fact, companies like Veritone are already offering services that allow influencers, athletes, and actors to license their AI voices for endorsements and radio idents without having to go into a studio. This indicates a future where influencers, actors, and celebrities could easily rent out their voices, boosting their income with minimal effort. It is clear that voice cloning technology has the potential to significantly impact industries and raise important ethical considerations.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run({\n",
    "    \"text_to_change\": text_to_change,\n",
    "    \"text_all\": text_all,\n",
    "    \"title\": title,\n",
    "    \"doc_1\": best_k_documents[0].page_content,\n",
    "    \"doc_2\": best_k_documents[1].page_content,\n",
    "    \"doc_3\": best_k_documents[2].page_content\n",
    "})\n",
    "\n",
    "print(\"Text to Change: \", text_to_change)\n",
    "print(\"**********************\")\n",
    "print(\"Expanded Variation:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d76179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
