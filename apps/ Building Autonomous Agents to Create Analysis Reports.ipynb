{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1790f12",
   "metadata": {},
   "source": [
    "# Building Autonomous Agents to Create Analysis Reports -  \"Plan and Execute\" LangChain agents \n",
    "\n",
    "STEPS:\n",
    "* [1. Setup](#setup)\n",
    "* [2. Saving Documents on Deep Lake](#saving)\n",
    "* [3. Creating a Document Retrieval Tool](#retrieval)\n",
    "* [4. Using the Plan and Execute Agent](#using)\n",
    "\n",
    "\n",
    "**Plan and Execute agents** are a new type of agent executor offering a different approach than the traditional agents supported in LangChain. These agents are heavily inspired by the BabyAGI framework and the recent Plan-and-Solve paper. Their primary goal is to enable more complex long-term planning, even at the cost of making more calls to the language model.\n",
    "\n",
    "Each \"Plan and Execute\" agent consists of:\n",
    "- **planner component** (utilizes an LLM's reasoning ability to plan out the required steps);\n",
    "- **executor component** (determines the appropriate tools or actions required to execute each step of the plan).\n",
    "\n",
    "\n",
    "USEFUL RESOURCES:\n",
    "- [Plan-and-Execute Agents](https://blog.langchain.dev/plan-and-execute-agents/)\n",
    "- [Activeloop's Deep Lake](https://python.langchain.com/docs/integrations/vectorstores/activeloop_deeplake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16687644",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"setup\">\n",
    "    \n",
    "## 1. Setup\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b9144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain==0.0.208 deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from keys import OPENAI_API_KEY, ACTIVELOOP_TOKEN\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e539be",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"saving\">\n",
    "    \n",
    "## 2. Saving Documents on Deep Lake\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7791de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scrape several Artificial Intelligence news\n",
    "\n",
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/23/meta-open-source-speech-ai-models-support-over-1100-languages/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/18/beijing-launches-campaign-against-ai-generated-misinformation/\"\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/eu-committees-green-light-ai-act/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/wozniak-warns-ai-will-power-next-gen-scams/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/infocepts-ceo-shashank-garg-on-the-da-market-shifts-and-impact-of-ai-on-data-analytics/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/26/ftc-chairwoman-no-ai-exemption-to-existing-laws/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/24/bill-gates-ai-teaching-kids-literacy-within-18-months/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/21/google-creates-new-ai-division-to-challenge-openai/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec410ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# We'll use an embedding model to compute our documents' embeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# We'll store the documents and their embeddings in the deep lake vector db\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# Setup deep lake\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# create Deep Lake dataset\n",
    "my_activeloop_org_id = \"iryna\"\n",
    "my_activeloop_dataset_name = \"langchain_course_analysis_outline\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14c65f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the article texts into small chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c0502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c304b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embedding data: 100%|███████████████████████████████| 8/8 [00:07<00:00,  1.08it/s]\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://iryna/langchain_course_analysis_outline', tensors=['embedding', 'id', 'metadata', 'text'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      " embedding  embedding  (94, 1536)  float32   None   \n",
      "    id        text      (94, 1)      str     None   \n",
      " metadata     json      (94, 1)      str     None   \n",
      "   text       text      (94, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0799cedc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799cfea-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d03a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d06c-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d09e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d0d0-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d102-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d134-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d166-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d198-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d1ca-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d1f2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d224-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d256-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d288-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d2b0-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d2e2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d314-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d346-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d378-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d3a0-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d3d2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d404-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d436-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d45e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d490-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d4c2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d4f4-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d526-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d54e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d580-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d5b2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d5da-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d616-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d63e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d670-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d6a2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d6d4-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d6fc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d72e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d760-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d792-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d7ba-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d7ec-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d81e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d850-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d878-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d8aa-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d8dc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d904-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d936-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d968-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d99a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d9cc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799d9f4-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799da26-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799da58-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799da8a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dab2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dae4-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799db16-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799db48-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799db70-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dba2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dbd4-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dce2-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dd1e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dd50-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dd78-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799ddaa-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dddc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799de0e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799de40-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799de68-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799de9a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799decc-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799defe-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799df3a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799df6c-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799df9e-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dfc6-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799dff8-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e02a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e05c-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e084-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e0b6-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e0e8-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e11a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e14c-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e174-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e1a6-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e1d8-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e20a-481c-11ee-aa94-12ee7aa5dbdc',\n",
       " '0799e23c-481c-11ee-aa94-12ee7aa5dbdc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add all the chunks to the Deep lake\n",
    "db.add_texts(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7389a86",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"retrieval\">\n",
    "    \n",
    "## 3. Creating a Document Retrieval Tool\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a260bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the retriever object from the deep lake db object and set the number of retrieved documents to 3\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['k'] = 3\n",
    "CUSTOM_TOOL_DOCS_SEPARATOR =\"\\n---------------\\n\" # how to join together the retrieved docs to form a single string\n",
    "\n",
    "\n",
    "# Function that defines the custom tool to retrieve relevant docs from DeepLake\n",
    "def retrieve_n_docs_tool(query: str) -> str:\n",
    "    \"\"\"Searches for relevant documents that may contain the answer to the query.\"\"\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    texts_merged = \"---------------\\n\" + CUSTOM_TOOL_DOCS_SEPARATOR.join(texts) + \"\\n---------------\"\n",
    "    return texts_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5876374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool\n",
    "\n",
    "# Create the tool that uses the \"retrieve_n_docs_tool\" function\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search Private Docs\",\n",
    "        func=retrieve_n_docs_tool,\n",
    "        description=\"useful for when you need to answer questions about current events about Artificial Intelligence\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34902d41",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"using\">\n",
    "    \n",
    "## 4. Using the Plan and Execute Agent\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60a86159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "\n",
    "# let's create the Plan and Execute agent\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "planner = load_chat_planner(model)\n",
    "executor = load_agent_executor(model, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b42379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n",
      "steps=[Step(value='Research and gather information on the current state of Artificial Intelligence regulations in the European Union.'), Step(value='Identify the key regulations and policies that have been implemented or proposed in the European Union regarding Artificial Intelligence.'), Step(value='Organize the gathered information into different categories such as ethical guidelines, data protection, liability, and transparency.'), Step(value='Summarize the main objectives and principles of the regulations in each category.'), Step(value='Provide examples of specific regulations or guidelines that have been implemented or proposed in the European Union.'), Step(value='Highlight any challenges or controversies surrounding the implementation of these regulations.'), Step(value='Conclude the overview by summarizing the overall impact and significance of Artificial Intelligence regulations in the European Union.'), Step(value=\"Given the above steps taken, respond to the user's original question. \\n\")]\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Artificial Intelligence regulations European Union\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered from the previous steps and the search in the private documents, here is an overview of the AI regulations in the European Union (EU):\n",
      "\n",
      "- The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm.\n",
      "- The AI Act aims to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "- Exemptions are provided for research activities and open-source AI components.\n",
      "- The EU promotes regulatory sandboxes for testing AI before deployment.\n",
      "- The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations and may be subject to change.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Research and gather information on the current state of Artificial Intelligence regulations in the European Union.\n",
      "\n",
      "Response: Based on the information gathered from the previous steps and the search in the private documents, here is an overview of the AI regulations in the European Union (EU):\n",
      "\n",
      "- The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm.\n",
      "- The AI Act aims to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "- Exemptions are provided for research activities and open-source AI components.\n",
      "- The EU promotes regulatory sandboxes for testing AI before deployment.\n",
      "- The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations and may be subject to change.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"European Union AI regulations\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mBased on the previous steps and the search in the private documents, the key regulations and policies that have been implemented in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Identify the key regulations and policies that have been implemented or proposed in the European Union regarding Artificial Intelligence.\n",
      "\n",
      "Response: Based on the previous steps and the search in the private documents, the key regulations and policies that have been implemented in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"ethical guidelines for AI\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "The rules are based on a risk-based approach and they establish obligations for providers and users depending on the level of risk that the AI system can generate. AI systems with an unacceptable level of risk to people’s safety would be strictly prohibited, including systems that deploy subliminal or purposefully manipulative techniques, exploit people’s vulnerabilities, or are used for social scoring.\n",
      "---------------\n",
      "In March, Musk joined Apple co-founder Steve Wozniak and over 1,000 other experts in signing an open letter calling for a halt to “out-of-control” AI development.\n",
      "\n",
      "However, some experts believe that AI can be developed in a way that benefits society. For example, AI can be used to diagnose diseases, detect fraud, and reduce traffic accidents.\n",
      "\n",
      "To ensure that AI is developed in a responsible and ethical manner, many organisations have developed guidelines, including the IEEE, the EU, and the OECD.\n",
      "\n",
      "The concerns raised by Hinton about AI are significant and highlight the need for responsible AI development. While AI has the potential to bring many benefits to society, it is crucial that it is developed in a way that minimises its risks and maximises its benefits.\n",
      "\n",
      "(Image Credit: Eviatar Bach under CC BY-SA 3.0 license. Image cropped from original.)\n",
      "---------------\n",
      "Altman’s call for regulation aligns with concerns raised by AI experts and ethicists, including former Google researchers Dr Timnit Gebru and Meredith Whitaker. They argue that the rapid adoption of AI is overhyped and fails to deliver inherent social good.\n",
      "\n",
      "Whitaker highlighted the concentration of power in the hands of a few tech companies and their ability to shape social and political landscapes through AI technologies. She expressed concerns about the existing power dynamics and emphasised the need for a more equitable distribution of AI capabilities.\n",
      "\n",
      "Whitaker cautioned against the notion that AI will automatically lead to social good or equal access for all, arguing that it is a fantasy propagated for marketing purposes. She stressed the importance of acknowledging the concentration of power and the need to ensure that AI is harnessed for the benefit of society as a whole.\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the previous steps, the gathered information has been organized into different categories such as ethical guidelines, data protection, liability, and transparency. However, I haven't seen any specific information related to these categories in the previous steps. To provide a more accurate response, I will search the private documents for information on ethical guidelines for AI.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"ethical guidelines for AI\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "The rules are based on a risk-based approach and they establish obligations for providers and users depending on the level of risk that the AI system can generate. AI systems with an unacceptable level of risk to people’s safety would be strictly prohibited, including systems that deploy subliminal or purposefully manipulative techniques, exploit people’s vulnerabilities, or are used for social scoring.\n",
      "---------------\n",
      "In March, Musk joined Apple co-founder Steve Wozniak and over 1,000 other experts in signing an open letter calling for a halt to “out-of-control” AI development.\n",
      "\n",
      "However, some experts believe that AI can be developed in a way that benefits society. For example, AI can be used to diagnose diseases, detect fraud, and reduce traffic accidents.\n",
      "\n",
      "To ensure that AI is developed in a responsible and ethical manner, many organisations have developed guidelines, including the IEEE, the EU, and the OECD.\n",
      "\n",
      "The concerns raised by Hinton about AI are significant and highlight the need for responsible AI development. While AI has the potential to bring many benefits to society, it is crucial that it is developed in a way that minimises its risks and maximises its benefits.\n",
      "\n",
      "(Image Credit: Eviatar Bach under CC BY-SA 3.0 license. Image cropped from original.)\n",
      "---------------\n",
      "Altman’s call for regulation aligns with concerns raised by AI experts and ethicists, including former Google researchers Dr Timnit Gebru and Meredith Whitaker. They argue that the rapid adoption of AI is overhyped and fails to deliver inherent social good.\n",
      "\n",
      "Whitaker highlighted the concentration of power in the hands of a few tech companies and their ability to shape social and political landscapes through AI technologies. She expressed concerns about the existing power dynamics and emphasised the need for a more equitable distribution of AI capabilities.\n",
      "\n",
      "Whitaker cautioned against the notion that AI will automatically lead to social good or equal access for all, arguing that it is a fantasy propagated for marketing purposes. She stressed the importance of acknowledging the concentration of power and the need to ensure that AI is harnessed for the benefit of society as a whole.\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search in the private documents, I found some information on ethical guidelines for AI. The rules are based on a risk-based approach and establish obligations for providers and users depending on the level of risk that the AI system can generate. AI systems with an unacceptable level of risk to people's safety would be strictly prohibited, including systems that deploy subliminal or purposefully manipulative techniques, exploit people's vulnerabilities, or are used for social scoring.\n",
      "\n",
      "Additionally, many organizations, including the IEEE, the EU, and the OECD, have developed guidelines to ensure that AI is developed in a responsible and ethical manner. These guidelines aim to minimize the risks associated with AI development and maximize its benefits.\n",
      "\n",
      "It is important to note that while AI has the potential to bring many benefits to society, there are concerns raised by experts and ethicists about the rapid adoption of AI and the concentration of power in the hands of a few tech companies. They emphasize the need for a more equitable distribution of AI capabilities and the responsible harnessing of AI for the benefit of society as a whole.\n",
      "\n",
      "Please let me know if there's anything else I can help with!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Organize the gathered information into different categories such as ethical guidelines, data protection, liability, and transparency.\n",
      "\n",
      "Response: Based on the search in the private documents, I found some information on ethical guidelines for AI. The rules are based on a risk-based approach and establish obligations for providers and users depending on the level of risk that the AI system can generate. AI systems with an unacceptable level of risk to people's safety would be strictly prohibited, including systems that deploy subliminal or purposefully manipulative techniques, exploit people's vulnerabilities, or are used for social scoring.\n",
      "\n",
      "Additionally, many organizations, including the IEEE, the EU, and the OECD, have developed guidelines to ensure that AI is developed in a responsible and ethical manner. These guidelines aim to minimize the risks associated with AI development and maximize its benefits.\n",
      "\n",
      "It is important to note that while AI has the potential to bring many benefits to society, there are concerns raised by experts and ethicists about the rapid adoption of AI and the concentration of power in the hands of a few tech companies. They emphasize the need for a more equitable distribution of AI capabilities and the responsible harnessing of AI for the benefit of society as a whole.\n",
      "\n",
      "Please let me know if there's anything else I can help with!\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Main objectives and principles of AI regulations in each category\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "The rules are based on a risk-based approach and they establish obligations for providers and users depending on the level of risk that the AI system can generate. AI systems with an unacceptable level of risk to people’s safety would be strictly prohibited, including systems that deploy subliminal or purposefully manipulative techniques, exploit people’s vulnerabilities, or are used for social scoring.\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered information on the main objectives and principles of the AI regulations in each category. Here is a summary:\n",
      "\n",
      "1. European Union (EU):\n",
      "- The AI Act categorizes AI systems based on their potential for harm.\n",
      "- The objectives are to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "- Exemptions are provided for research activities and open-source AI components.\n",
      "- The EU promotes regulatory sandboxes for testing AI before deployment.\n",
      "- Citizens have the right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "- The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "2. United Kingdom (UK):\n",
      "- The UK is adopting a similar approach to the US in AI regulation.\n",
      "- Due to its proximity to the EU market, the UK may also align with the EU ruleset.\n",
      "- The potential to experiment in a regulatory sandbox may be attractive for UK-based developers.\n",
      "\n",
      "3. United States (US):\n",
      "- The US tech approach is typically to experiment first and then retrofit to other markets and regulatory frameworks.\n",
      "- US-based AI developers may have an advantage over their European competitors in terms of innovation.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations and may be subject to change. Let me know if there's anything else I can help with!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Summarize the main objectives and principles of the regulations in each category.\n",
      "\n",
      "Response: I have gathered information on the main objectives and principles of the AI regulations in each category. Here is a summary:\n",
      "\n",
      "1. European Union (EU):\n",
      "- The AI Act categorizes AI systems based on their potential for harm.\n",
      "- The objectives are to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "- Exemptions are provided for research activities and open-source AI components.\n",
      "- The EU promotes regulatory sandboxes for testing AI before deployment.\n",
      "- Citizens have the right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "- The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "2. United Kingdom (UK):\n",
      "- The UK is adopting a similar approach to the US in AI regulation.\n",
      "- Due to its proximity to the EU market, the UK may also align with the EU ruleset.\n",
      "- The potential to experiment in a regulatory sandbox may be attractive for UK-based developers.\n",
      "\n",
      "3. United States (US):\n",
      "- The US tech approach is typically to experiment first and then retrofit to other markets and regulatory frameworks.\n",
      "- US-based AI developers may have an advantage over their European competitors in terms of innovation.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations and may be subject to change. Let me know if there's anything else I can help with!\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"specific regulations or guidelines implemented or proposed in the European Union\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "MEPs also substantially amended the list of prohibited AI practices to include bans on intrusive and discriminatory uses of AI systems, such as real-time remote biometric identification systems in publicly accessible spaces, post-remote biometric identification systems (except for law enforcement purposes), biometric categorisation systems using sensitive characteristics, predictive policing systems, emotion recognition systems in law enforcement, border management, workplace, and educational institutions, and indiscriminate scraping of biometric data from social media or CCTV footage to create facial recognition databases.\n",
      "\n",
      "MEPs also expanded the classification of high-risk areas to include harm to people’s health, safety, fundamental rights, or the environment. They also added AI systems that influence voters in political campaigns and recommender systems used by social media platforms to the high-risk list.\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the previous steps, the specific regulations or guidelines that have been implemented or proposed in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change. Let me know if there's anything else I can help with!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Provide examples of specific regulations or guidelines that have been implemented or proposed in the European Union.\n",
      "\n",
      "Response: Based on the previous steps, the specific regulations or guidelines that have been implemented or proposed in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change. Let me know if there's anything else I can help with!\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Challenges and controversies surrounding the implementation of AI regulations\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "Altman’s call for regulation aligns with concerns raised by AI experts and ethicists, including former Google researchers Dr Timnit Gebru and Meredith Whitaker. They argue that the rapid adoption of AI is overhyped and fails to deliver inherent social good.\n",
      "\n",
      "Whitaker highlighted the concentration of power in the hands of a few tech companies and their ability to shape social and political landscapes through AI technologies. She expressed concerns about the existing power dynamics and emphasised the need for a more equitable distribution of AI capabilities.\n",
      "\n",
      "Whitaker cautioned against the notion that AI will automatically lead to social good or equal access for all, arguing that it is a fantasy propagated for marketing purposes. She stressed the importance of acknowledging the concentration of power and the need to ensure that AI is harnessed for the benefit of society as a whole.\n",
      "---------------\n",
      "As AI continues to advance, the conversation surrounding its regulation and responsible deployment becomes increasingly important. Balancing the potential benefits with the risks and ensuring equitable access and distribution of AI technologies are key challenges that policymakers, researchers, and industry leaders must address collectively.\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "---------------\n",
      "Wozniak was one of around 1,000 technology experts who put their names to a letter in March calling for a six-month pause on the development of some AI tools so that guidelines for their safe deployment can be drawn up.\n",
      "\n",
      "He wants the regulation of major tech companies that “feel they can kind of get away with anything” to ensure that they stay within certain boundaries. However, Wozniak also pondered whether such regulation would be effective, stating that “the forces that drive for money usually win out, which is sort of sad.”\n",
      "\n",
      "As AI technology continues to evolve, it is essential to ensure that its use is regulated to prevent cybercriminals from using it for fraudulent activities. At the same time, it is vital to balance regulation with innovation to enable AI technology to be developed in a responsible and safe manner.\n",
      "\n",
      "Similar: AI ‘godfather’ warns of dangers and quits Google\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the previous steps, I can see that the human is looking for information on the challenges or controversies surrounding the implementation of AI regulations. I can provide some relevant information from the private documents. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Challenges and controversies surrounding the implementation of AI regulations\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "Altman’s call for regulation aligns with concerns raised by AI experts and ethicists, including former Google researchers Dr Timnit Gebru and Meredith Whitaker. They argue that the rapid adoption of AI is overhyped and fails to deliver inherent social good.\n",
      "\n",
      "Whitaker highlighted the concentration of power in the hands of a few tech companies and their ability to shape social and political landscapes through AI technologies. She expressed concerns about the existing power dynamics and emphasised the need for a more equitable distribution of AI capabilities.\n",
      "\n",
      "Whitaker cautioned against the notion that AI will automatically lead to social good or equal access for all, arguing that it is a fantasy propagated for marketing purposes. She stressed the importance of acknowledging the concentration of power and the need to ensure that AI is harnessed for the benefit of society as a whole.\n",
      "---------------\n",
      "As AI continues to advance, the conversation surrounding its regulation and responsible deployment becomes increasingly important. Balancing the potential benefits with the risks and ensuring equitable access and distribution of AI technologies are key challenges that policymakers, researchers, and industry leaders must address collectively.\n",
      "\n",
      "Want to learn more about AI and big data from industry leaders? Check out AI & Big Data Expo taking place in Amsterdam, California, and London. The event is co-located with Digital Transformation Week.\n",
      "\n",
      "Explore other upcoming enterprise technology events and webinars powered by TechForge here.\n",
      "---------------\n",
      "Wozniak was one of around 1,000 technology experts who put their names to a letter in March calling for a six-month pause on the development of some AI tools so that guidelines for their safe deployment can be drawn up.\n",
      "\n",
      "He wants the regulation of major tech companies that “feel they can kind of get away with anything” to ensure that they stay within certain boundaries. However, Wozniak also pondered whether such regulation would be effective, stating that “the forces that drive for money usually win out, which is sort of sad.”\n",
      "\n",
      "As AI technology continues to evolve, it is essential to ensure that its use is regulated to prevent cybercriminals from using it for fraudulent activities. At the same time, it is vital to balance regulation with innovation to enable AI technology to be developed in a responsible and safe manner.\n",
      "\n",
      "Similar: AI ‘godfather’ warns of dangers and quits Google\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search in the private documents, I found some information on the challenges and controversies surrounding the implementation of AI regulations. Some of the concerns raised\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Highlight any challenges or controversies surrounding the implementation of these regulations.\n",
      "\n",
      "Response: Based on the search in the private documents, I found some information on the challenges and controversies surrounding the implementation of AI regulations. Some of the concerns raised\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"Artificial Intelligence regulations impact and significance in the European Union\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mThe previous steps have provided a comprehensive overview of the AI regulations in the European Union (EU). The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The main objectives of the AI Act are to ensure that AI systems are safe, transparent, traceable, and non-discriminatory. The EU also promotes regulatory sandboxes for testing AI before deployment and has exemptions for research activities and open-source AI components. The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "The impact and significance of AI regulations in the European Union are significant. These regulations aim to protect individuals and ensure that AI systems are developed and used responsibly. By categorizing AI systems based on their potential for harm, the EU is taking a proactive approach to mitigate risks associated with AI. The exemptions for research activities and open-source AI components encourage innovation while ensuring that ethical considerations are taken into account. The promotion of regulatory sandboxes allows for safe testing and development of AI technologies. Overall, the AI regulations in the European Union set a framework for responsible AI development and usage.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The impact and significance of AI regulations in the European Union are significant. These regulations aim to protect individuals and ensure that AI systems are developed and used responsibly. By categorizing AI systems based on their potential for harm, the EU is taking a proactive approach to mitigate risks associated with AI. The exemptions for research activities and open-source AI components encourage innovation while ensuring that ethical considerations are taken into account. The promotion of regulatory sandboxes allows for safe testing and development of AI technologies. Overall, the AI regulations in the European Union set a framework for responsible AI development and usage.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Conclude the overview by summarizing the overall impact and significance of Artificial Intelligence regulations in the European Union.\n",
      "\n",
      "Response: The impact and significance of AI regulations in the European Union are significant. These regulations aim to protect individuals and ensure that AI systems are developed and used responsibly. By categorizing AI systems based on their potential for harm, the EU is taking a proactive approach to mitigate risks associated with AI. The exemptions for research activities and open-source AI components encourage innovation while ensuring that ethical considerations are taken into account. The promotion of regulatory sandboxes allows for safe testing and development of AI technologies. Overall, the AI regulations in the European Union set a framework for responsible AI development and usage.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Based on the information gathered from the previous steps and the search in the private documents, the key regulations and policies that have been implemented in the European Union regarding Artificial Intelligence (AI) are as follows:\\n\\n1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\\n\\n2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\\n\\n3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\\n\\n4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\\n\\n5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\\n\\nPlease note that this information is based on the current state of AI regulations in the European Union and may be subject to change.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Given the above steps taken, respond to the user's original question. \n",
      "\n",
      "\n",
      "Response: Based on the information gathered from the previous steps and the search in the private documents, the key regulations and policies that have been implemented in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "response = agent.run(\"Write an overview of Artificial Intelligence regulations in European Union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc940e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information gathered from the previous steps and the search in the private documents, the key regulations and policies that have been implemented in the European Union regarding Artificial Intelligence (AI) are as follows:\n",
      "\n",
      "1. AI Act: The EU has recently green-lit the AI Act, which categorizes AI systems based on their potential for harm. The aim of the AI Act is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "2. Exemptions for Research Activities and Open-Source AI Components: To boost AI innovation, the AI Act includes exemptions for research activities and AI components provided under open-source licenses.\n",
      "\n",
      "3. Regulatory Sandboxes: The EU promotes regulatory sandboxes, which are controlled environments established by public authorities, to test AI before its deployment.\n",
      "\n",
      "4. Citizens' Rights: The AI Act aims to boost citizens' rights by allowing them to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights.\n",
      "\n",
      "5. Role of the EU AI Office: The EU AI Office is responsible for monitoring the implementation of the AI rulebook.\n",
      "\n",
      "Please note that this information is based on the current state of AI regulations in the European Union and may be subject to change.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69af390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langenv",
   "language": "python",
   "name": "langenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
